<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Homework 1</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Homework 1</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#spark-35-pts" id="toc-spark-35-pts">Spark (35 pts)</a>
<ul>
<li><a href="#what-to-submit" id="toc-what-to-submit">What to
submit</a></li>
</ul></li>
<li><a href="#association-rules-45-pts"
id="toc-association-rules-45-pts">Association Rules (45 pts)</a>
<ul>
<li><a href="#a-4pts" id="toc-a-4pts">(a) [4pts]</a></li>
<li><a href="#b-5pts" id="toc-b-5pts">(b) [5pts]</a></li>
<li><a href="#c-6pts" id="toc-c-6pts">(c) [6pts]</a></li>
<li><a href="#d-15pts" id="toc-d-15pts">(d) [15pts]</a></li>
<li><a href="#e-15pts" id="toc-e-15pts">(e) [15pts]</a></li>
<li><a href="#what-to-submit-1" id="toc-what-to-submit-1">What to
submit</a></li>
</ul></li>
<li><a href="#locality-sensitive-hashing-20-pts"
id="toc-locality-sensitive-hashing-20-pts">Locality-Sensitive Hashing
(20 pts)</a>
<ul>
<li><a href="#a-7pts" id="toc-a-7pts">(a) [7pts]</a></li>
<li><a href="#b-7pts" id="toc-b-7pts">(b) [7pts]</a></li>
<li><a href="#c-6pts-1" id="toc-c-6pts-1">(c) [6pts]</a></li>
<li><a href="#what-to-submit-2" id="toc-what-to-submit-2">What to
submit</a></li>
</ul></li>
</ul>
</nav>
<p><br />
</p>
<h1 id="spark-35-pts">Spark (35 pts)</h1>
<p>Write a Spark program that implements a simple “People You Might
Know” social network friendship recommendation algorithm. The key idea
is that if two people have a lot of mutual friends, then the system
should recommend that they connect with each other.</p>
<p><span><strong>Data:</strong></span></p>
<ul>
<li><p>Associated data file is in
<span><code>q1/data</code></span>.</p></li>
<li><p>The file contains the adjacency list and has multiple lines in
the following format:</p>
<p><span><code>&lt;User&gt;&lt;TAB&gt;&lt;Friends&gt;</code></span></p>
<p>Here, <span><code>&lt;User&gt;</code></span> is a unique integer ID
corresponding to a unique user and
<span><code>&lt;Friends&gt;</code></span> is a comma separated list of
unique IDs corresponding to the friends of the user with the unique ID
<span><code>&lt;User&gt;</code></span>. Note that the friendships are
mutual (i.e., edges are undirected): if <span
class="math inline">\(A\)</span> is friend with <span
class="math inline">\(B\)</span> then <span
class="math inline">\(B\)</span> is also friend with <span
class="math inline">\(A\)</span>. The data provided is consistent with
that rule as there is an explicit entry for each side of each
edge.</p></li>
</ul>
<p><span><strong>Algorithm:</strong></span> Let us use a simple
algorithm such that, for each user <span
class="math inline">\(U\)</span>, the algorithm recommends <span
class="math inline">\(N=10\)</span> users who are not already friends
with <span class="math inline">\(U\)</span>, but have the most number of
mutual friends in common with <span
class="math inline">\(U\)</span>.</p>
<p><span><strong>Output:</strong></span></p>
<ul>
<li><p>The output should contain one line per user in the following
format:</p>
<p><span><code>&lt;User&gt;&lt;TAB&gt;&lt;Recommendations&gt;</code></span></p>
<p>where <span><code>&lt;User&gt;</code></span> is a unique ID
corresponding to a user and
<span><code>&lt;Recommendations&gt;</code></span> is a comma separated
list of unique IDs corresponding to the algorithm’s recommendation of
people that <span><code>&lt;User&gt;</code></span> might know, ordered
in decreasing number of mutual friends.</p></li>
<li><p>Even if a user has less than 10 second-degree friends, output all
of them in decreasing order of the number of mutual friends. If a user
has no friends, you can provide an empty list of recommendations. If
there are recommended users with the same number of mutual friends, then
output those user IDs in numerically ascending order.</p></li>
</ul>
<p><span><strong>Pipeline sketch:</strong></span> Please provide a
description of how you used Spark to solve this problem. Don’t write
more than 3 to 4 sentences for this: we only want a very high-level
description of your strategy to tackle this problem.</p>
<p><span><strong>Tips:</strong></span></p>
<ul>
<li><p>Before submitting a complete application to Spark, you may use
the Shell to go line by line, checking the outputs of each step. Command
<span><code>.take(X)</code></span> should be helpful, if you want to
check the first <span><code>X</code></span> elements in the
RDD.</p></li>
<li><p>For sanity check, your top 10 recommendations for <strong>user ID
11</strong> should be:<br />
<span><code>27552,7785,27573,27574,27589,27590,27600,27617,27620,27667</code></span>.</p></li>
<li><p>The default memory assigned to the Spark runtime may not be
enough to process this data file, depending on how you write your
algorithm. If your Spark job fails with a message starting as:</p>
<pre data-fontsize="\scriptsize"><code>17/12/28 10:50:35 INFO DAGScheduler: Job 0 failed: sortByKey at FriendsRecomScala.scala:45, took 519.084974 s
Exception in thread &quot;main&quot; org.apache.spark.SparkException:
Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure:
Lost task 0.0 in stage 2.0 (TID 4, localhost, executor driver)</code></pre>
<p>then you’ll very likely need to increase the memory assigned to the
Spark runtime. If you are running in stand-alone mode (i.e. you did not
setup a Spark cluster), use <span><code>–driver-memory 8G</code></span>
to set the runtime memory to 8GB. If you are running on a Spark cluster,
use <span><code>–executor-memory 8G</code></span> to set the memory to
8GB.</p></li>
</ul>
<h2 class="unnumbered" id="what-to-submit">What to submit</h2>
<ol type="1">
<li><p>Upload your code to Gradescope.</p></li>
<li><p>Include in your writeup a short paragraph sketching your spark
pipeline.</p></li>
<li><p>Include in your writeup the recommendations for the users with
following user IDs: 924, 8941, 8942, 9019, 9020, 9021, 9022, 9990, 9992,
9993.</p></li>
</ol>
<h1 id="association-rules-45-pts">Association Rules (45 pts)</h1>
<p>Association Rules are frequently used for Market Basket Analysis
(MBA) by retailers to understand the purchase behavior of their
customers. This information can be then used for many different purposes
such as cross-selling and up-selling of products, sales promotions,
loyalty programs, store design, discount plans and many others.</p>
<p><strong>Evaluation of item sets:</strong> Once you have found the
frequent itemsets of a dataset, you need to choose a subset of them as
your recommendations. Commonly used metrics for measuring significance
and interest for selecting rules for recommendations are:</p>
<ol>
<li><p><strong>Confidence</strong> (denoted as <span
class="math inline">\(\mathop{\mathrm{conf}}(A \rightarrow B)\)</span>):
<em>Confidence</em> is defined as the empirical estimate of the
probability <span class="math inline">\(\Pr(B|A)\)</span>, the
probability of finding item set <span class="math inline">\(B\)</span>
given that item set <span class="math inline">\(A\)</span> is present:
<span class="math display">\[\mathop{\mathrm{conf}}(A \rightarrow B) =
\frac{\mathop{\mathrm{Support}}(A \cup
B)}{\mathop{\mathrm{Support}}(A)},\]</span></p></li>
<li><p><strong>Lift</strong> (denoted as <span
class="math inline">\(\mathop{\mathrm{lift}}(A \rightarrow B)\)</span>):
<em>Lift</em> measures how much more “<span
class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span> occur together” than “what would be
expected if <span class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span> were statistically independent”: <span
class="math display">\[\mathop{\mathrm{lift}}(A \rightarrow B) =
\frac{\mathop{\mathrm{conf}}(A \rightarrow B)}{S(B)},\]</span> where
<span class="math inline">\(S(B) =
\frac{\mathop{\mathrm{Support}}(B)}{N}\)</span> is an estimate of <span
class="math inline">\(\Pr(B)\)</span>, the probability of <span
class="math inline">\(B\)</span> appearing in a transaction (basket),
and <span class="math inline">\(N=\text{total number of
transactions}\)</span>.</p></li>
<li><p><strong>Conviction</strong> (denoted as <span
class="math inline">\(\mathop{\mathrm{conv}}(A \rightarrow B)\)</span>):
<em>Conviction</em> compares the “probability that <span
class="math inline">\(A\)</span> appears without <span
class="math inline">\(B\)</span> if they were independent” with the
“actual frequency of the appearance of <span
class="math inline">\(A\)</span> without <span
class="math inline">\(B\)</span>”: <span
class="math display">\[\mathop{\mathrm{conv}}(A \rightarrow B) =
\frac{1-S(B)}{1-\mathop{\mathrm{conf}}(A \rightarrow
B)}.\]</span></p></li>
</ol>
<h3 class="unnumbered" id="a-4pts">(a) [4pts]</h3>
<p>A drawback of using <em>confidence</em> is that it ignores <span
class="math inline">\(\Pr(B)\)</span>. Why is this a drawback? Explain
why <em>lift</em> and <em>conviction</em> do not suffer from this
drawback.</p>
<h3 class="unnumbered" id="b-5pts">(b) [5pts]</h3>
<p>A measure is <em>symmetrical</em> if <span
class="math inline">\(\text{measure}(A \rightarrow B) = \text{measure}(B
\rightarrow A)\)</span>. Which of the measures presented here are
symmetrical? For each measure, please provide either a proof that the
measure is symmetrical, or a counterexample that shows the measure is
not symmetrical.</p>
<h3 class="unnumbered" id="c-6pts">(c) [6pts]</h3>
<p><em>Perfect implications</em> are rules that hold 100% of the time
(or equivalently, the associated conditional probability is 1). A
measure is <em>desirable</em> if it reaches its maximum achievable value
for all perfect implications. This makes it easy to identify the best
rules.</p>
<p>For each of the aforementioned measures, if it is desirable prove
that it is. Otherwise, provide a dataset in which not all perfect
implications have the same value for this measure (which proves it is
not desirable). You may ignore <span class="math inline">\(0/0\)</span>,
but we will define <span class="math inline">\(c/0 = \pm
\infty\)</span>, where the sign matches the sign of <span
class="math inline">\(c\)</span>.</p>
<h4 id="application-in-product-recommendations">Application in product
recommendations:</h4>
<p>The action or practice of selling additional products or services to
existing customers is called <em>cross-selling</em>. Giving product
recommendation is one of the examples of cross-selling that are
frequently used by online retailers. One simple method to give product
recommendations is to recommend products that are frequently browsed
together by the customers.</p>
<p>Suppose we want to recommend new products to the customer based on
the products they have already browsed online. Implement the
<em>A-priori</em> algorithm and write a program using your
implementation to find products which are frequently browsed together.
Fix the support to <span class="math inline">\(s=\)</span>100
(<em>i.e.</em> product pairs need to occur together at least 100 times
to be considered frequent) and find itemsets of size 2 and 3.</p>
<p>Use the online browsing behavior dataset from in
<span><code>q2/data</code></span>. Each line represents a browsing
session of a customer. On each line, each string of 8 characters
represents the ID of an item browsed during that session. The items are
separated by spaces.</p>
<p>Note: for parts (d) and (e), the writeup will require a specific rule
ordering but the program need not sort the output. We are not giving
partial credits to coding when results are wrong. However, two sanity
checks are provided and they should be helpful when you progress: (1)
there are 647 frequent items after <span
class="math inline">\(1^{\textrm{st}}\)</span> pass (<span
class="math inline">\(|L_1|=647\)</span>), (2) the top 5 pairs you
should produce in part (d) all have confidence scores greater than
0.985. See detailed instructions below. You don’t need to use Spark
unless you want to.</p>
<h3 class="unnumbered" id="d-15pts">(d) [15pts]</h3>
<p>Identify pairs of items <span class="math inline">\((X,Y)\)</span>
such that the support of <span class="math inline">\(\{X,Y\}\)</span> is
at least <span class="math inline">\(100\)</span>. For all such pairs,
compute the <em>confidence</em> scores of the corresponding association
rules: <span class="math inline">\(X \Rightarrow Y\)</span>, <span
class="math inline">\(Y \Rightarrow X\)</span>. Sort the rules in
decreasing order of <em>confidence</em> scores and list the top 5 rules
in the writeup. Break ties, if any, by lexicographically increasing
order on the left hand side of the rule.</p>
<h3 class="unnumbered" id="e-15pts">(e) [15pts]</h3>
<p>Identify item triples <span class="math inline">\((X,Y,Z)\)</span>
such that the support of <span class="math inline">\(\{X,Y,Z\}\)</span>
is at least <span class="math inline">\(100\)</span>. For all such
triples, compute the <em>confidence</em> scores of the corresponding
association rules: <span class="math inline">\((X,Y) \Rightarrow
Z\)</span>, <span class="math inline">\((X,Z) \Rightarrow Y\)</span>,
<span class="math inline">\((Y,Z) \Rightarrow X\)</span>. Sort the rules
in decreasing order of <em>confidence</em> scores and list the top 5
rules in the writeup. Order the left-hand-side pair lexicographically
and break ties, if any, by lexicographical order of the first then the
second item in the pair.</p>
<h2 class="unnumbered" id="what-to-submit-1">What to submit</h2>
<p>Upload all the code to Gradescope and include the following in your
writeup:</p>
<ol type="i">
<li><p>Explanation for 2(a).</p></li>
<li><p>Proofs and/or counterexamples for 2(b).</p></li>
<li><p>Explanation for 2(c).</p></li>
<li><p>Top 5 rules with confidence scores [2(d)].</p></li>
<li><p>Top 5 rules with confidence scores [2(e)].</p></li>
</ol>
<h1 id="locality-sensitive-hashing-20-pts">Locality-Sensitive Hashing
(20 pts)</h1>
<p>When simulating a random permutation of rows, as described in
<strong>Sect. 3.3.5</strong> of MMDS, we could save time if we
restricted our attention to a randomly chosen <span
class="math inline">\(k\)</span> of the <span
class="math inline">\(n\)</span> rows, rather than hashing all <span
class="math inline">\(n\)</span> row numbers. The downside of doing so
is that, if none of the <span class="math inline">\(k\)</span> rows
contains a <span class="math inline">\(1\)</span> in a certain column,
then the result of the minhashing is “don’t know”. In other words, we
get no row number as the minhash value. It would be a mistake to assume
that two columns that both minhash to “don’t know” are likely to be
similar. However, if the probability of getting “don’t know” as a
minhash value is small, we can tolerate the situation and simply ignore
such minhash values when computing the fraction of minhashes in which
two columns agree.</p>
<p>In part (a) we determine an upper bound on the probability of getting
“don’t know” as the minhash value when considering only a <span
class="math inline">\(k\)</span>-subset of the <span
class="math inline">\(n\)</span> rows, and in part (b) we use this bound
to determine an appropriate choice for <span
class="math inline">\(k\)</span>, given our tolerance for this
probability.</p>
<h3 class="unnumbered" id="a-7pts">(a) [7pts]</h3>
<p>Suppose a column has <span class="math inline">\(m\)</span> 1’s and
therefore <span class="math inline">\(n-m\)</span> 0’s, and we randomly
choose k rows to consider when computing the minhash. Prove that the
probability of getting “don’t know” as the minhash value for this column
is at most <span class="math inline">\((\frac{n-k}{n})^m\)</span>.</p>
<h3 class="unnumbered" id="b-7pts">(b) [7pts]</h3>
<p>Suppose we want the probability of “don’t know” to be at most <span
class="math inline">\(e^{-10}\)</span>. Assuming <span
class="math inline">\(n\)</span> and <span
class="math inline">\(m\)</span> are both very large (but <span
class="math inline">\(n\)</span> is much larger than <span
class="math inline">\(m\)</span> or <span
class="math inline">\(k\)</span>), give a simple approximation to the
smallest value of <span class="math inline">\(k\)</span> that will
ensure this probability is at most <span
class="math inline">\(e^{-10}\)</span>. Your expression should be a
function of <span class="math inline">\(n\)</span> and <span
class="math inline">\(m\)</span>. Hints: (1) Part a. (2) Remember that
for any <span class="math inline">\(x \in \mathbb{R}\)</span>, <span
class="math inline">\(1 + x \le e^x\)</span>.</p>
<h3 class="unnumbered" id="c-6pts-1">(c) [6pts]</h3>
<p>Note: Part (c) should be considered separate from the previous two
parts, in that we are no longer restricting our attention to a randomly
chosen subset of the rows.</p>
<p>When minhashing, one might expect that we could estimate the Jaccard
similarity without using all possible permutations of rows. For example,
we could only allow cyclic permutations, i.e. start at a randomly chosen
row <span class="math inline">\(r\)</span>, which becomes the first in
the order, followed by rows <span class="math inline">\(r + 1\)</span>,
<span class="math inline">\(r + 2\)</span>, and so on, down to the last
row, and then continuing with the first row, second row, and so on, down
to row <span class="math inline">\(r - 1\)</span>. There are only <span
class="math inline">\(n\)</span> such permutations if there are <span
class="math inline">\(n\)</span> rows. However, these permutations are
not sufficient to estimate the Jaccard similarity correctly.</p>
<p>Give an example of two columns such that the probability (over cyclic
permutations only) that their minhash values agree is not the same as
their Jaccard similarity. In your answer, please provide (a) an example
of a matrix with two columns (let the two columns correspond to sets
denoted by <span class="math inline">\(S1\)</span> and <span
class="math inline">\(S2\)</span>), (b) the Jaccard similarity of <span
class="math inline">\(S1\)</span> and <span
class="math inline">\(S2\)</span>, and (c) the probability that a random
cyclic permutation yields the same minhash value for both <span
class="math inline">\(S1\)</span> and <span
class="math inline">\(S2\)</span>.</p>
<h2 class="unnumbered" id="what-to-submit-2">What to submit</h2>
<p>Include the following in your writeup:</p>
<ol type="i">
<li><p>Proof for 3(a)</p></li>
<li><p>Derivation and final answer for 3(b)</p></li>
<li><p>Example for 3(c) including the three requested items</p></li>
</ol>
</body>
</html>
